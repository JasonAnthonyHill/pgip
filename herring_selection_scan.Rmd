---
title: "pgip example selection scan"
author: "Student"
date: "`r Sys.Date()`"
output: html_document
---

# Selection scan example using data from Atlantic herring

Welcome to the selection scan example. In this module we will work with pooled data from the Atlantic herring. Using pooled population resequencing we will select two groups of populations to contrast and identify a recent strong selective sweep. This code is provided for instruction and may serve as a template for your own work in the future.

## Load require libraries

Our approach in this example is designed to be as basic and transparent as possible. There are many methods available to scan for haplotype variation between populations but today you will be using a simple and robust method which is good at detecting selective sweeps.

You will require just a few installed libraries to implement the ΔAlleleFrequency-χ2 method:
*knitr* - Allows the implementation of rmarkdown
*tidyverse* - Implements the syntax conventions and plotting tools used in this exercise
*vcfR* - Enables the reading and manipulation of variant call files
*data.table* - Additional data manipulation utilities used herein

Please install these libraries if you do not already have them available and run the code chunk below.

```{r setup}
# This code block is complete, run as is.
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(vcfR)
library(data.table)
```

# Loading of variant calls and initial filtering

## Load vcf

For the sake of space and speed you will limit your analysis to a 7MB chunk of chromosome 4, however this method is easilly extensible to whole genome analysis.

```{r load vcf}
# This code bloci is complete, run as is
chr4_vcf <- read.vcfR("Ch_v2.0.2_envPools_chr4subregion.vcf.gz")
```

## Convert vcf to a dataframe

First you want to convert the vcf file to a dataframe for easier manipulation within R. You will also only keep the information that is useful this analysis. VCF files contain a lot of information, but this method is only concerned with allele counts within populations. For example, genotype calls are not relevant since we are working with pooled samples, and will be doing population pooling later.

```{r vcf to df}
# This code block is complete, run as is.
chr4.df <- chr4_vcf %>% 
  vcfR2tidy(single_frame = TRUE) %>% 
  .$dat %>% 
  dplyr::select(POS, Indiv, gt_AD) %>% 
  drop_na() %>% 
  mutate(snp_number = row_number()) %>% 
  separate(gt_AD, c("ref","alt"), sep = ",", convert = T)

view(chr4.df)
```
## *Exercise* Answer the following question

Q. What do the numbers in the ref and alt columns represent?

A.

## Filtering 

One of the reasons this method is good to apply, especially at the beginning of a project, is that it is robust to irregularities in the variant calling step. As such minimal filtering is required, which as a general rule is a good thing. However it is still usefull to remove sites from the analysis that have extreme high or low coverage, and sites which have missing data from too many populations. 

Look at the median coverage of the data. Then plot the coverage and filter to remove the sites at the tails of the distribution. 

```{r depth filter}
# This code block is incomplete, please complete the following before running.
# 1) Variables $min and $max must be replaced with numerical values
# 2) ggplot function is incomplete

medcov <- chr4.df %>% # Calculate median coverage
  summarise(med=median(ref+alt)) %>% 
  .[['med']]

medcov # Display median coverage

# Use ggplot or another method of your choice to visualise or examine the distribution of coverages, and choose a min and max cutoff

ggplot(data = chr4.df, aes(x = ref+alt)) + # Add ggplot geoms to visualise coverage

alleles_rh1_depth_filt <- chr4.df %>% # Filter out sites outside of coverage range
  filter((ref+alt >= $min) & (ref + alt <= $max))
```

Now count the number of populations we have and remove sites that don't have a minimum number of populations represented. This should generally be a strict filter, at least 70%.

```{r missing filter}
# This code block is incomplete, please complete the following before running.
# 1) fraction of population $missingness must be defined
numberpops <- alleles_rh1_depth_filt %>%  # Number of pops, improve
  group_by(POS) %>% 
  summarise(ns = n()) %>% 
  ungroup() %>% 
  arrange(-ns) %>% 
  slice(1) %>% 
  .[['ns']]

alleles_rh1_filt <- alleles_rh1_depth_filt %>% 
  group_by(POS) %>% 
  filter(n() > $missingness) %>% 
  ungroup()
```


# Define Groups

Now your data is ready for testing. We discussed the nature of the data you are working with and which populations we are going to contrast. 
You will now define the members of the two groups used in your comparison. Often you will have phenotypic or environmental variables that you will use to define the members of the contrasting groups. In the case of these herring populations, you have painstakingly gathered environmental information regarding the salinity, water clarity, and red light absorbance at each of your sample sites. Use some or all of these criteria to divide your samples into two groups. Your motivation is to identify the genetic variants that may have been under selection in these different environmental regimes.



## Load the data
```{r environmental variables}
# This code block is complete, run as is.
environmental_vars <- read_csv("rh1_poolAF_secchi_sal_abs_20190204.csv") %>% 
  select(vcfpops, lon, lat, secchi, Salinity, Absorbance_412nm) %>% 
  drop_na()
```
## Exercise on contrast selection

In the code block below view the data and use plotting functions to understand the distribution of variables.

lon = longitude
lat = latitude
secchi = water clarity (higher values = clearer water)
Salinity = salinity (higher values = more salty)
Absorbance_412nm = red light absorbance (higher values = more red light absorbed, less red light penetrates the water column)

```{r environmental variable exploration}
# This code block is a template for exploring the environmental variables. Alter as necessary to visualize the different variables.
View(environmental_vars)

 ggplot(data = environmental_vars) +
   geom_point(aes(x = lon, y = lat, color = Salinity, size = secchi)) +
   # geom_text(aes(x = lon, y = lat, label = vcfpops), vjust = -1) + # Uncomment to add population names
   scale_color_viridis_c() +
   theme_minimal()
```

Our purpose of the exploration is to define the members of the two groups that will be contrasted in the genomic scan. Using insight gained from the differences seen in the environmental variables data define the members of the two contrast groups. Make sure each group is about the same size. Use the vcfpops in the environment_vars data.
```{r define contrast groups}
# This code block is incomplete. Fill the character vectors for group1 and group2
# population names can come from chr4.df$Indiv or environmental_vars$vcfpops
group1 <- c("A_Example_population_name","B_A_different_example_population_name")
group2 <- c("Z_Another_Example_population_name")
```


# Define functions used for statistical tests

You will define your own functions to pool the group allele counts, calculate the ΔAlleleFrequency, and apply a manually defined χ2 function to test for the statistical significance of deviation from expected allele frequences between the populations. If you have questions about the specifics of the functions feel free to ask.

The codeblock below is complete, run it to load the manually defined statistical tests into the environment.
```{r define functions}
# This code block is complete, run as is
groupsum <- function(dfin,group1,group2) {
  dfin %>%
    mutate(group = ifelse(grepl(paste(group1,collapse="|"), Indiv), "group1",
                          ifelse(grepl(paste(group2,collapse="|"), Indiv), "group2", NA))) %>% 
    group_by(group, POS) %>% 
    summarise(ref = sum(ref), alt = sum(alt)) %>%  
    ungroup() %>% 
    arrange(POS)
}

chiFunc <- function(x,y) {
  a1 <- x[1]
  a2 <- y[1]
  b1 <- x[2]
  b2 <- y[2]
  sumall <- a1+a2+b1+b2
  expectA1 <- (a1 + a2)*(a1 + b1)/sumall
  expectA2 <- (a1 + a2)*(a2 + b2)/sumall
  expectB1 <- (b1 + b2)*(a1 + b1)/sumall
  expectB2 <- (b1 + b2)*(a2 + b2)/sumall
  chi <- (a1 - expectA1)^2 / expectA1 + 
    (a2 - expectA2)^2 / expectA2 + 
    (b1 - expectB1)^2 / expectB1 + 
    (b2 - expectB2)^2 / expectB1
  return(chi)
}

dafFunc <- function(ref,alt) {
  ref_A <- ref[1]
  alt_A <- alt[1]
  ref_B <- ref[2]
  alt_B <- alt[2]
  refAFA <- ref_A/(ref_A+alt_A)
  altAFA <- alt_A/(ref_A+alt_A)
  refAFB <- ref_B/(ref_B+alt_B)
  altAFB <- alt_B/(ref_B+alt_B)
  refdeltaAF <- abs(refAFA - refAFB)
  return(refdeltaAF)
}

chi_daf_test <- function(x) {
  a <- x %>% 
    group_by(POS) %>%
    mutate(refsum = sum(ref), altsum = sum(alt)) %>% 
    filter(refsum > 0 & altsum > 0) %>% 
    select(-altsum, -refsum) %>%
    summarise(chisq = chiFunc(ref,alt)) %>% 
    mutate(logpval = -log(pchisq(chisq,1,lower.tail=FALSE), base = 10))
  b <- x %>% 
    group_by(POS) %>% 
    summarise(daf = dafFunc(ref,alt))
  y <- full_join(x, b) 
  z <- full_join(y,a)
  return(z)
}
```

# Calculate group allele sums

You are interested in whether the allele frequencies between two groups of samples is significantly different. We will therefore count all the alleles in each contrast group and use those totals for our x2 test.


```{r groupsums}
# This code block is complete, run as is.
groupsums <- groupsum(alleles_rh1_filt, group1, group2) %>% 
  filter(!is.na(group))
```

# Calculate ΔAlleleFrequency and χ2 statistic

Now that you have your pools of allele counts, you will calculate the difference in allele frequency between the two groups at each SNP site and use χ2 to determine if those differences are statistically significant. After generating the dAFchi dataframe you may inspect it to see the numerical results of the ΔAlleleFrequency and statistical test.

```{r dAF_chi2}
# This code block is complete, run as is.
dAFchi <- groupsums %>%
  chi_daf_test()

chitest <- dAFchi %>%
  drop_na() %>% 
  select(POS, logpval) %>% 
  distinct()
```

# Plot results

Now that you have generated the statistics you can visualize the results. One layout that is informative is to plot the -log(p-value) on the y axis and the genomic coordinate on the x-axis. If the data spans multiple chromosomes you would end up with a familliar manhattan plot. In our case we are looking at a section of a single chromosome.

```{r}
# This code block is complete, run as is.
chitest %>% 
  ggplot() + 
  geom_point(aes(x = POS, y = logpval), alpha = .25) + 
  theme_bw() +
  theme(plot.margin = margin(t = 10, unit = "pt")) +
  labs(x = "Chr 4 bp", y = "Chi squared log(p-val)")
```

There is a known strong selective sweep in this region that correlates with salinity and light absorbance measurements. If you selected populations to contrast that captured the extremes of these ranges, you should see a clear selective sweep present in the plot. A very good selection should produce a peak that reaches a -log(p-value) of at least 40. Try a few different combinations of groups, and observe how strongly the sweep is detected.

## *Exercise*
In the space below, record the groups used in a ΔAlleleFrequency contrast and the characteristics of the sweep

Trial 1
 - group 1:
 - group 2:
 - max -log(p-value):
 - Other observations (changes in filtering, etc.):

Trial 2
 - group 1:
 - group 2:
 - max -log(p-value):
 - Other observations (changes in filtering, etc.):
 
# Functional relevance of SNPs

Once the region under selection is identified, the work of identifying the causal mutations begins. This process can become complicated but some basic tests can sometimes yield interesting results. The VCF file you have been working with includes annotations from SNPEff. SNPEff uses a gene annotation to assign probably effects to SNPs identified in the VCF file. These fit numerous categories and can be useful for attributing functional changes to genetic changes.

Read back in the vcf file, this time isolating the annotation fields.

```{r read ANN}
# This code block is complete, run as is.
info.chr4.df <- chr4_vcf %>% 
  vcfR2tidy(single_frame = TRUE) %>% 
  .$dat %>% 
  dplyr::select(POS, Indiv, ANN) %>% 
  separate(ANN, into = c(NA, "Variant_Type"), extra = "drop", sep = '\\|')
```

Now you can merge this SNP annotation with your chitest data and visualize the effects of the SNPs in your sweep region. There are many different categories but I always like to see if there are any protein code changing SNPs in the sweep regions I look at.

```{r merge ANN and plot}
# This code block is complete, run as is. The most recently run chitest data is used here,
# so run your best one in the previous steps again before moving on to this.
combined <- chitest %>% 
  left_join(info.chr4.df) %>%
    select(-Indiv) %>% 
  distinct() %>% 
  mutate(Variant_Type = if_else(grepl("missense", Variant_Type), "missense", "other"))

combined %>% 
  ggplot() + 
  geom_point(aes(x = POS, y = logpval, color = Variant_Type), alpha = .25) + 
  geom_point(data = combined %>% 
               filter(Variant_Type == "missense"),
             aes(x = POS, y = logpval, color = Variant_Type)) +
  theme_bw() +
  theme(plot.margin = margin(t = 10, unit = "pt")) +
  labs(x = "Chr 4 bp", y = "Chi squared log(p-val)")

```

These missense mutations in the center of the sweep correspond to amino acid changes in the rhodopsin protein. If these seem interesting then the next step would be to undertake structural and functional studies on how these mutations may be influencing the activity of the gene.

